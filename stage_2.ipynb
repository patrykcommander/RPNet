{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second stage of the OSIOSN project\n",
    "\n",
    "### Creating and training baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, cat\n",
    "from torch.nn import Conv1d, ConvTranspose1d, MaxPool1d, Dropout, ReLU, Sequential, Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"./dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load(os.path.join(DATASET_PATH, \"x_train.npy\"))\n",
    "y_train = np.load(os.path.join(DATASET_PATH, \"x_train.npy\"))\n",
    "\n",
    "x_test = np.load(os.path.join(DATASET_PATH, \"x_train.npy\"))\n",
    "y_test = np.load(os.path.join(DATASET_PATH, \"x_train.npy\"))\n",
    "\n",
    "x_val = np.load(os.path.join(DATASET_PATH, \"x_train.npy\"))\n",
    "y_val = np.load(os.path.join(DATASET_PATH, \"x_train.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "batch_size = 5\n",
    "lr = 1e-3\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Nauka sieci realizowana bÄ™dzie na:',device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data shape [batch_size, channels, samples]\n",
    "\n",
    "class Conv1DBlock(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, kernel_size):\n",
    "    super(Conv1DBlock, self).__init__()\n",
    "    self.conv1d = Conv1d(in_channels, out_channels, kernel_size, padding=\"same\")\n",
    "    self.relu = ReLU(inplace=True)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.conv1d(x)\n",
    "    x = self.relu(x)\n",
    "    return x\n",
    "\n",
    "class DoubleConv1DBlock(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, kernel_size):\n",
    "    super(DoubleConv1DBlock, self).__init__()\n",
    "    self.double_conv = Sequential(\n",
    "      Conv1DBlock(in_channels, out_channels, kernel_size),\n",
    "      Conv1DBlock(out_channels, out_channels, kernel_size)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.double_conv(x)\n",
    "\n",
    "\n",
    "class DownSample1DBlock(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, kernel_size, dropout=0.3):\n",
    "    super(DownSample1DBlock, self).__init__()\n",
    "    self.double_conv = DoubleConv1DBlock(in_channels, out_channels, kernel_size)\n",
    "    self.maxpool_1d = MaxPool1d(kernel_size=2)\n",
    "    self.dropout = Dropout(dropout)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.double_conv(x)\n",
    "    pool = self.maxpool_1d(x)\n",
    "    return x, self.dropout(pool)\n",
    "\n",
    "\n",
    "class UpSample1DBlock(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, kernel_size, dropout=0.3):\n",
    "    super(UpSample1DBlock, self).__init__()\n",
    "    self.conv1d_transpose = ConvTranspose1d(in_channels, out_channels, kernel_size=2, stride=2)\n",
    "    self.double_conv = DoubleConv1DBlock(in_channels, out_channels, kernel_size)\n",
    "    self.dropout = Dropout(dropout)\n",
    "\n",
    "  def forward(self, x, conv_features):\n",
    "    x = self.conv1d_transpose(x)\n",
    "    print(x.size())\n",
    "    print(conv_features.size())\n",
    "    x = cat([x, conv_features], dim=1)\n",
    "    x = self.dropout(x)\n",
    "    return self.double_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RPNet(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels):\n",
    "    super(RPNet, self).__init__()\n",
    "    self.d1 = DownSample1DBlock(in_channels, 16, 3)\n",
    "    self.d2 = DownSample1DBlock(16, 32, 3)\n",
    "    self.d3 = DownSample1DBlock(32, 64, 3)\n",
    "\n",
    "    self.bottleneck = DoubleConv1DBlock(64, 128, 3)\n",
    "    \n",
    "    self.u1 = UpSample1DBlock(128, 64, 3)\n",
    "    self.u2 = UpSample1DBlock(64, 32, 3)\n",
    "    self.u3 = UpSample1DBlock(32, 16, 3)\n",
    "\n",
    "    self.output = Conv1d(16, out_channels, kernel_size=1)\n",
    "    self.sigmoid = Sigmoid()\n",
    "\n",
    "  def forward(self, x):\n",
    "    f1, p1 = self.d1(x)\n",
    "    f2, p2 = self.d2(p1)\n",
    "    f3, p3 = self.d3(p2)\n",
    "    \n",
    "    bottleneck = self.bottleneck(p3)\n",
    "\n",
    "    u1 = self.u1(bottleneck, f3)\n",
    "    u2 = self.u2(u1, f2)\n",
    "    u3 = self.u3(u2, f1)\n",
    "\n",
    "    output = self.output(u3)\n",
    "    return self.sigmoid(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 250])\n",
      "torch.Size([1, 64, 250])\n",
      "torch.Size([1, 32, 500])\n",
      "torch.Size([1, 32, 500])\n",
      "torch.Size([1, 16, 1000])\n",
      "torch.Size([1, 16, 1000])\n",
      "tensor([[[0.5420, 0.5432, 0.5414, 0.5428, 0.5422, 0.5442, 0.5432, 0.5445,\n",
      "          0.5443, 0.5461, 0.5435, 0.5434, 0.5458, 0.5431, 0.5424, 0.5466,\n",
      "          0.5440, 0.5453, 0.5395, 0.5432, 0.5428, 0.5398, 0.5428, 0.5415,\n",
      "          0.5433, 0.5442, 0.5405, 0.5450, 0.5405, 0.5457, 0.5428, 0.5433,\n",
      "          0.5431, 0.5463, 0.5426, 0.5436, 0.5401, 0.5431, 0.5402, 0.5469,\n",
      "          0.5427, 0.5465, 0.5418, 0.5437, 0.5446, 0.5413, 0.5414, 0.5414,\n",
      "          0.5450, 0.5467, 0.5442, 0.5422, 0.5430, 0.5427, 0.5440, 0.5408,\n",
      "          0.5407, 0.5428, 0.5440, 0.5442, 0.5443, 0.5418, 0.5445, 0.5451,\n",
      "          0.5414, 0.5427, 0.5406, 0.5401, 0.5398, 0.5409, 0.5438, 0.5416,\n",
      "          0.5476, 0.5418, 0.5431, 0.5396, 0.5446, 0.5424, 0.5390, 0.5455,\n",
      "          0.5436, 0.5442, 0.5414, 0.5464, 0.5405, 0.5414, 0.5436, 0.5468,\n",
      "          0.5445, 0.5414, 0.5437, 0.5396, 0.5431, 0.5445, 0.5409, 0.5405,\n",
      "          0.5439, 0.5472, 0.5413, 0.5449, 0.5432, 0.5417, 0.5405, 0.5424,\n",
      "          0.5447, 0.5435, 0.5439, 0.5411, 0.5439, 0.5451, 0.5470, 0.5408,\n",
      "          0.5422, 0.5435, 0.5449, 0.5435, 0.5458, 0.5423, 0.5437, 0.5439,\n",
      "          0.5469, 0.5417, 0.5405, 0.5473, 0.5453, 0.5417, 0.5428, 0.5410,\n",
      "          0.5433, 0.5433, 0.5422, 0.5442, 0.5381, 0.5416, 0.5439, 0.5432,\n",
      "          0.5438, 0.5397, 0.5440, 0.5461, 0.5443, 0.5413, 0.5424, 0.5433,\n",
      "          0.5443, 0.5428, 0.5410, 0.5420, 0.5424, 0.5433, 0.5423, 0.5448,\n",
      "          0.5379, 0.5421, 0.5424, 0.5443, 0.5413, 0.5451, 0.5413, 0.5474,\n",
      "          0.5442, 0.5417, 0.5400, 0.5442, 0.5394, 0.5409, 0.5420, 0.5437,\n",
      "          0.5481, 0.5412, 0.5422, 0.5392, 0.5371, 0.5418, 0.5467, 0.5442,\n",
      "          0.5400, 0.5429, 0.5399, 0.5449, 0.5425, 0.5403, 0.5399, 0.5419,\n",
      "          0.5395, 0.5414, 0.5403, 0.5432, 0.5442, 0.5456, 0.5436, 0.5414,\n",
      "          0.5406, 0.5430, 0.5412, 0.5438, 0.5425, 0.5416, 0.5452, 0.5453,\n",
      "          0.5451, 0.5428, 0.5437, 0.5458, 0.5436, 0.5420, 0.5442, 0.5474,\n",
      "          0.5421, 0.5419, 0.5425, 0.5417, 0.5459, 0.5483, 0.5443, 0.5393,\n",
      "          0.5391, 0.5404, 0.5441, 0.5423, 0.5438, 0.5425, 0.5441, 0.5432,\n",
      "          0.5464, 0.5444, 0.5434, 0.5440, 0.5405, 0.5439, 0.5448, 0.5419,\n",
      "          0.5403, 0.5411, 0.5445, 0.5427, 0.5433, 0.5425, 0.5412, 0.5440,\n",
      "          0.5408, 0.5436, 0.5464, 0.5433, 0.5438, 0.5433, 0.5429, 0.5475,\n",
      "          0.5439, 0.5410, 0.5421, 0.5466, 0.5442, 0.5444, 0.5433, 0.5412,\n",
      "          0.5449, 0.5437, 0.5415, 0.5395, 0.5428, 0.5440, 0.5444, 0.5440,\n",
      "          0.5434, 0.5421, 0.5437, 0.5428, 0.5438, 0.5454, 0.5423, 0.5399,\n",
      "          0.5450, 0.5427, 0.5455, 0.5436, 0.5351, 0.5421, 0.5468, 0.5442,\n",
      "          0.5415, 0.5463, 0.5426, 0.5460, 0.5437, 0.5426, 0.5439, 0.5399,\n",
      "          0.5442, 0.5458, 0.5446, 0.5444, 0.5430, 0.5395, 0.5438, 0.5428,\n",
      "          0.5422, 0.5439, 0.5432, 0.5396, 0.5406, 0.5465, 0.5428, 0.5428,\n",
      "          0.5441, 0.5442, 0.5447, 0.5404, 0.5442, 0.5402, 0.5437, 0.5467,\n",
      "          0.5402, 0.5436, 0.5480, 0.5427, 0.5417, 0.5446, 0.5428, 0.5464,\n",
      "          0.5431, 0.5453, 0.5419, 0.5435, 0.5408, 0.5444, 0.5435, 0.5453,\n",
      "          0.5424, 0.5446, 0.5409, 0.5443, 0.5431, 0.5445, 0.5424, 0.5417,\n",
      "          0.5424, 0.5402, 0.5450, 0.5452, 0.5393, 0.5417, 0.5403, 0.5450,\n",
      "          0.5434, 0.5462, 0.5452, 0.5429, 0.5399, 0.5426, 0.5422, 0.5469,\n",
      "          0.5398, 0.5442, 0.5451, 0.5419, 0.5417, 0.5406, 0.5389, 0.5486,\n",
      "          0.5433, 0.5461, 0.5416, 0.5434, 0.5442, 0.5415, 0.5439, 0.5428,\n",
      "          0.5462, 0.5485, 0.5417, 0.5440, 0.5446, 0.5428, 0.5430, 0.5437,\n",
      "          0.5451, 0.5429, 0.5411, 0.5443, 0.5457, 0.5447, 0.5399, 0.5409,\n",
      "          0.5445, 0.5422, 0.5436, 0.5401, 0.5432, 0.5473, 0.5449, 0.5438,\n",
      "          0.5448, 0.5430, 0.5424, 0.5437, 0.5415, 0.5408, 0.5423, 0.5427,\n",
      "          0.5413, 0.5456, 0.5436, 0.5434, 0.5416, 0.5444, 0.5440, 0.5416,\n",
      "          0.5485, 0.5412, 0.5429, 0.5466, 0.5437, 0.5415, 0.5427, 0.5439,\n",
      "          0.5431, 0.5441, 0.5405, 0.5454, 0.5401, 0.5433, 0.5486, 0.5435,\n",
      "          0.5403, 0.5449, 0.5409, 0.5423, 0.5413, 0.5463, 0.5456, 0.5445,\n",
      "          0.5431, 0.5413, 0.5436, 0.5401, 0.5408, 0.5454, 0.5393, 0.5422,\n",
      "          0.5404, 0.5409, 0.5421, 0.5418, 0.5424, 0.5411, 0.5398, 0.5472,\n",
      "          0.5439, 0.5441, 0.5419, 0.5407, 0.5423, 0.5415, 0.5455, 0.5438,\n",
      "          0.5413, 0.5425, 0.5437, 0.5407, 0.5437, 0.5411, 0.5433, 0.5458,\n",
      "          0.5436, 0.5471, 0.5401, 0.5425, 0.5427, 0.5400, 0.5429, 0.5412,\n",
      "          0.5433, 0.5443, 0.5455, 0.5451, 0.5382, 0.5442, 0.5401, 0.5456,\n",
      "          0.5441, 0.5450, 0.5386, 0.5442, 0.5456, 0.5404, 0.5401, 0.5445,\n",
      "          0.5407, 0.5418, 0.5440, 0.5430, 0.5420, 0.5459, 0.5428, 0.5396,\n",
      "          0.5430, 0.5429, 0.5434, 0.5461, 0.5417, 0.5449, 0.5380, 0.5416,\n",
      "          0.5413, 0.5425, 0.5423, 0.5459, 0.5378, 0.5469, 0.5428, 0.5421,\n",
      "          0.5470, 0.5437, 0.5415, 0.5437, 0.5454, 0.5430, 0.5417, 0.5457,\n",
      "          0.5434, 0.5430, 0.5460, 0.5437, 0.5374, 0.5486, 0.5445, 0.5362,\n",
      "          0.5417, 0.5433, 0.5467, 0.5455, 0.5414, 0.5459, 0.5414, 0.5420,\n",
      "          0.5446, 0.5436, 0.5368, 0.5414, 0.5431, 0.5414, 0.5421, 0.5443,\n",
      "          0.5410, 0.5429, 0.5420, 0.5447, 0.5431, 0.5384, 0.5419, 0.5435,\n",
      "          0.5436, 0.5438, 0.5419, 0.5447, 0.5439, 0.5418, 0.5413, 0.5435,\n",
      "          0.5418, 0.5437, 0.5413, 0.5463, 0.5432, 0.5425, 0.5472, 0.5432,\n",
      "          0.5418, 0.5457, 0.5466, 0.5402, 0.5455, 0.5437, 0.5417, 0.5439,\n",
      "          0.5400, 0.5431, 0.5421, 0.5462, 0.5399, 0.5426, 0.5431, 0.5423,\n",
      "          0.5449, 0.5464, 0.5394, 0.5415, 0.5452, 0.5452, 0.5427, 0.5444,\n",
      "          0.5407, 0.5416, 0.5466, 0.5406, 0.5431, 0.5410, 0.5393, 0.5452,\n",
      "          0.5399, 0.5405, 0.5469, 0.5430, 0.5427, 0.5423, 0.5428, 0.5455,\n",
      "          0.5424, 0.5446, 0.5408, 0.5420, 0.5431, 0.5437, 0.5470, 0.5437,\n",
      "          0.5409, 0.5440, 0.5448, 0.5427, 0.5424, 0.5410, 0.5452, 0.5454,\n",
      "          0.5404, 0.5444, 0.5437, 0.5409, 0.5452, 0.5409, 0.5424, 0.5428,\n",
      "          0.5434, 0.5422, 0.5391, 0.5462, 0.5456, 0.5415, 0.5416, 0.5472,\n",
      "          0.5423, 0.5439, 0.5424, 0.5401, 0.5434, 0.5424, 0.5435, 0.5450,\n",
      "          0.5403, 0.5415, 0.5452, 0.5450, 0.5475, 0.5421, 0.5418, 0.5425,\n",
      "          0.5429, 0.5432, 0.5409, 0.5415, 0.5477, 0.5394, 0.5402, 0.5445,\n",
      "          0.5447, 0.5414, 0.5404, 0.5414, 0.5420, 0.5409, 0.5451, 0.5463,\n",
      "          0.5425, 0.5420, 0.5408, 0.5431, 0.5451, 0.5449, 0.5454, 0.5393,\n",
      "          0.5415, 0.5420, 0.5401, 0.5452, 0.5456, 0.5410, 0.5415, 0.5420,\n",
      "          0.5430, 0.5444, 0.5434, 0.5446, 0.5396, 0.5431, 0.5470, 0.5410,\n",
      "          0.5401, 0.5417, 0.5461, 0.5394, 0.5419, 0.5420, 0.5476, 0.5415,\n",
      "          0.5407, 0.5459, 0.5419, 0.5409, 0.5443, 0.5446, 0.5422, 0.5409,\n",
      "          0.5412, 0.5462, 0.5384, 0.5416, 0.5452, 0.5440, 0.5410, 0.5360,\n",
      "          0.5386, 0.5413, 0.5443, 0.5418, 0.5439, 0.5429, 0.5436, 0.5416,\n",
      "          0.5432, 0.5463, 0.5407, 0.5417, 0.5484, 0.5420, 0.5401, 0.5452,\n",
      "          0.5411, 0.5440, 0.5455, 0.5429, 0.5439, 0.5446, 0.5410, 0.5441,\n",
      "          0.5409, 0.5450, 0.5453, 0.5429, 0.5437, 0.5429, 0.5467, 0.5444,\n",
      "          0.5450, 0.5407, 0.5441, 0.5443, 0.5414, 0.5455, 0.5434, 0.5427,\n",
      "          0.5449, 0.5451, 0.5407, 0.5381, 0.5476, 0.5437, 0.5464, 0.5431,\n",
      "          0.5386, 0.5437, 0.5408, 0.5460, 0.5428, 0.5410, 0.5442, 0.5427,\n",
      "          0.5443, 0.5448, 0.5463, 0.5409, 0.5430, 0.5446, 0.5417, 0.5456,\n",
      "          0.5439, 0.5438, 0.5429, 0.5436, 0.5433, 0.5452, 0.5426, 0.5460,\n",
      "          0.5415, 0.5391, 0.5464, 0.5450, 0.5443, 0.5453, 0.5412, 0.5439,\n",
      "          0.5464, 0.5429, 0.5427, 0.5408, 0.5471, 0.5426, 0.5404, 0.5442,\n",
      "          0.5450, 0.5431, 0.5441, 0.5432, 0.5422, 0.5431, 0.5414, 0.5421,\n",
      "          0.5426, 0.5414, 0.5423, 0.5449, 0.5443, 0.5433, 0.5405, 0.5408,\n",
      "          0.5399, 0.5486, 0.5397, 0.5394, 0.5415, 0.5441, 0.5435, 0.5441,\n",
      "          0.5405, 0.5467, 0.5445, 0.5426, 0.5459, 0.5413, 0.5382, 0.5454,\n",
      "          0.5418, 0.5417, 0.5428, 0.5420, 0.5405, 0.5400, 0.5434, 0.5458,\n",
      "          0.5450, 0.5451, 0.5450, 0.5407, 0.5402, 0.5416, 0.5414, 0.5448,\n",
      "          0.5430, 0.5411, 0.5420, 0.5396, 0.5455, 0.5441, 0.5446, 0.5414,\n",
      "          0.5434, 0.5431, 0.5421, 0.5441, 0.5394, 0.5435, 0.5438, 0.5450,\n",
      "          0.5420, 0.5435, 0.5435, 0.5450, 0.5414, 0.5437, 0.5447, 0.5449,\n",
      "          0.5439, 0.5422, 0.5386, 0.5432, 0.5426, 0.5426, 0.5406, 0.5447,\n",
      "          0.5421, 0.5468, 0.5434, 0.5461, 0.5424, 0.5408, 0.5447, 0.5467,\n",
      "          0.5426, 0.5469, 0.5421, 0.5420, 0.5450, 0.5430, 0.5421, 0.5445,\n",
      "          0.5429, 0.5449, 0.5441, 0.5434, 0.5424, 0.5407, 0.5399, 0.5481,\n",
      "          0.5406, 0.5406, 0.5472, 0.5447, 0.5425, 0.5413, 0.5422, 0.5433,\n",
      "          0.5426, 0.5459, 0.5437, 0.5422, 0.5414, 0.5364, 0.5355, 0.5375,\n",
      "          0.5432, 0.5449, 0.5471, 0.5438, 0.5400, 0.5399, 0.5439, 0.5414,\n",
      "          0.5462, 0.5434, 0.5404, 0.5428, 0.5414, 0.5436, 0.5465, 0.5412,\n",
      "          0.5439, 0.5444, 0.5400, 0.5467, 0.5413, 0.5438, 0.5448, 0.5434,\n",
      "          0.5423, 0.5422, 0.5449, 0.5419, 0.5421, 0.5431, 0.5422, 0.5469,\n",
      "          0.5437, 0.5424, 0.5411, 0.5407, 0.5452, 0.5422, 0.5471, 0.5473,\n",
      "          0.5394, 0.5434, 0.5407, 0.5441, 0.5465, 0.5431, 0.5420, 0.5465,\n",
      "          0.5414, 0.5449, 0.5397, 0.5428, 0.5432, 0.5424, 0.5475, 0.5438,\n",
      "          0.5441, 0.5420, 0.5437, 0.5436, 0.5406, 0.5455, 0.5445, 0.5445,\n",
      "          0.5420, 0.5437, 0.5439, 0.5417, 0.5437, 0.5421, 0.5438, 0.5462]]],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "rpnet = RPNet(in_channels=1, out_channels=1)\n",
    "input_data = torch.randn(1, 1, int(10 * 100))  # Example input data\n",
    "output_data = rpnet(input_data)\n",
    "print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
