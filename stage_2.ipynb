{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second stage of the OSIOSN project\n",
    "\n",
    "### Creating and training baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, cat\n",
    "from torch.nn import Conv1d, ConvTranspose1d, MaxPool1d, Dropout, ReLU, Sequential, Sigmoid\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"E:\\\\ml-data\\\\masters-thesis\\\\physionet.org\\\\files\\\\apnea-ecg\\\\1.0.0\\\\dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.expand_dims(np.load(os.path.join(DATASET_PATH, \"x_train.npy\")), 1)[:10000]\n",
    "y_train = np.expand_dims(np.load(os.path.join(DATASET_PATH, \"y_train.npy\")), 1)[:10000]\n",
    "\n",
    "x_test = np.expand_dims(np.load(os.path.join(DATASET_PATH, \"x_test.npy\")), 1)[:2500]\n",
    "y_test = np.expand_dims(np.load(os.path.join(DATASET_PATH, \"y_test.npy\")), 1)[:2500]\n",
    "\n",
    "x_val = np.expand_dims(np.load(os.path.join(DATASET_PATH, \"x_val.npy\")), 1)[:1000]\n",
    "y_val = np.expand_dims(np.load(os.path.join(DATASET_PATH, \"y_val.npy\")), 1)[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training will be performed with: cuda:0\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "batch_size = 20\n",
    "lr = 1e-3\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Training will be performed with:',device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data shape [batch_size, channels, samples]\n",
    "\n",
    "class Conv1DBlock(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, kernel_size):\n",
    "    super(Conv1DBlock, self).__init__()\n",
    "    self.conv1d = Conv1d(in_channels, out_channels, kernel_size, padding=\"same\")\n",
    "    self.relu = ReLU(inplace=True)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.conv1d(x)\n",
    "    x = self.relu(x)\n",
    "    return x\n",
    "\n",
    "class DoubleConv1DBlock(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, kernel_size):\n",
    "    super(DoubleConv1DBlock, self).__init__()\n",
    "    self.double_conv = Sequential(\n",
    "      Conv1DBlock(in_channels, out_channels, kernel_size),\n",
    "      Conv1DBlock(out_channels, out_channels, kernel_size)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.double_conv(x)\n",
    "\n",
    "\n",
    "class DownSample1DBlock(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, kernel_size, dropout=0.3):\n",
    "    super(DownSample1DBlock, self).__init__()\n",
    "    self.double_conv = DoubleConv1DBlock(in_channels, out_channels, kernel_size)\n",
    "    self.maxpool_1d = MaxPool1d(kernel_size=2)\n",
    "    self.dropout = Dropout(dropout)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.double_conv(x)\n",
    "    pool = self.maxpool_1d(x)\n",
    "    return x, self.dropout(pool)\n",
    "\n",
    "\n",
    "class UpSample1DBlock(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, kernel_size, dropout=0.3):\n",
    "    super(UpSample1DBlock, self).__init__()\n",
    "    self.conv1d_transpose = ConvTranspose1d(in_channels, out_channels, kernel_size=2, stride=2)\n",
    "    self.double_conv = DoubleConv1DBlock(in_channels, out_channels, kernel_size)\n",
    "    self.dropout = Dropout(dropout)\n",
    "\n",
    "  def forward(self, x, conv_features):\n",
    "    x = self.conv1d_transpose(x)\n",
    "    x = cat([x, conv_features], dim=1)\n",
    "    x = self.dropout(x)\n",
    "    return self.double_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGDataset(Dataset):\n",
    "  def __init__(self, data, labels):\n",
    "    super(ECGDataset, self).__init__()\n",
    "    self.data = data\n",
    "    self.labels = labels\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.data.shape[0]\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    sample = torch.tensor(self.data[idx], dtype=torch.float32)\n",
    "    label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "    return sample, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RPNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, lr=1e-3):\n",
    "        super(RPNet, self).__init__()\n",
    "        self.d1 = DownSample1DBlock(in_channels, 16, 3)\n",
    "        self.d2 = DownSample1DBlock(16, 32, 3)\n",
    "        self.d3 = DownSample1DBlock(32, 64, 3)\n",
    "\n",
    "        self.bottleneck = DoubleConv1DBlock(64, 128, 3)\n",
    "\n",
    "        self.u1 = UpSample1DBlock(128, 64, 3)\n",
    "        self.u2 = UpSample1DBlock(64, 32, 3)\n",
    "        self.u3 = UpSample1DBlock(32, 16, 3)\n",
    "\n",
    "        self.output = Conv1d(16, out_channels, kernel_size=1)\n",
    "        self.sigmoid = Sigmoid()\n",
    "\n",
    "        self.criterion = nn.BCELoss()\n",
    "        self.optimizer = Adam(self.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = x.transpose(1,2)\n",
    "\n",
    "        f1, p1 = self.d1(x)\n",
    "        f2, p2 = self.d2(p1)\n",
    "        f3, p3 = self.d3(p2)\n",
    "\n",
    "        bottleneck = self.bottleneck(p3)\n",
    "\n",
    "        u1 = self.u1(bottleneck, f3)\n",
    "        u2 = self.u2(u1, f2)\n",
    "        u3 = self.u3(u2, f1)\n",
    "\n",
    "        output = self.output(u3)\n",
    "        return self.sigmoid(output)\n",
    "\n",
    "    def train_model(self, x_train, y_train, epochs=10, batch_size=1, x_val=None, y_val=None,):\n",
    "        self.batch_size = batch_size\n",
    "        dataset = ECGDataset(x_train, y_train)\n",
    "        train_loader = DataLoader(dataset, batch_size, shuffle=False)\n",
    "\n",
    "        if x_val is not None:\n",
    "            validation_dataset = ECGDataset(x_val, y_val)\n",
    "            validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            running_loss = 0.0\n",
    "            num_r_peaks = 0.0\n",
    "            num_correct = 0.0\n",
    "\n",
    "            all_outputs = []\n",
    "            all_labels = []\n",
    "\n",
    "            self.train()\n",
    "            for i, (x, y) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "                x, y = x.to(device), y.to(device)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self(x)\n",
    "\n",
    "                loss = self.criterion(outputs, y)\n",
    "                running_loss += loss.item()\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                outputs = outputs.cpu().detach().numpy()\n",
    "                y = y.cpu().detach().numpy()\n",
    "\n",
    "                num_r_peaks += np.where(y == 1)[0].shape[0]\n",
    "                num_correct += np.where((outputs > 0.5) & (y == 1))[0].shape[0]\n",
    "\n",
    "                all_outputs.extend(outputs.flatten())\n",
    "                all_labels.extend(y.flatten())\n",
    "            \n",
    "            all_outputs = np.array(all_outputs)\n",
    "            all_labels = np.array(all_labels)\n",
    "            y_pred_binary = (all_outputs > 0.5).astype(int)\n",
    "\n",
    "            print(f\"====Epoch [{epoch + 1}/{epochs}]====\")\n",
    "            print(f\"\\nTrain Loss: {running_loss / len(train_loader):.4f}\")\n",
    "            self.calculate_metrics(num_correct, num_r_peaks, all_labels, y_pred_binary, phase=\"Train\")\n",
    "        \n",
    "            if x_val is not None:\n",
    "                self.validate(validation_loader)\n",
    "  \n",
    "    def validate(self, validation_loader):\n",
    "        self.eval()\n",
    "        running_vloss = 0.0\n",
    "        num_r_peaks = 0.0\n",
    "        num_correct = 0.0\n",
    "\n",
    "        all_outputs = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (x_val, y_val) in tqdm(enumerate(validation_loader), total=len(validation_loader)):\n",
    "                x, y = x_val.to(device), y_val.to(device)\n",
    "                outputs = self(x)\n",
    "\n",
    "                loss = self.criterion(outputs, y)\n",
    "                running_vloss += loss.item()\n",
    "\n",
    "                outputs = outputs.cpu().detach().numpy()\n",
    "                y = y.cpu().detach().numpy()\n",
    "\n",
    "                num_r_peaks += np.where(y == 1)[0].shape[0]\n",
    "                num_correct += np.where((outputs > 0.5) & (y == 1))[0].shape[0]\n",
    "\n",
    "                all_outputs.extend(outputs.flatten())\n",
    "                all_labels.extend(y.flatten())\n",
    "\n",
    "            all_outputs = np.array(all_outputs)\n",
    "            all_labels = np.array(all_labels)\n",
    "            y_pred_binary = (all_outputs > 0.5).astype(int)\n",
    "\n",
    "            print(f\"\\nValidation Loss: {running_vloss / len(validation_loader):.4f}\")\n",
    "            self.calculate_metrics(num_correct, num_r_peaks, all_labels, y_pred_binary, phase=\"Validation\")\n",
    "    \n",
    "    def test_model(self, x_test, y_test, plot=False):\n",
    "        test_dataset = ECGDataset(x_test, y_test)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=10, shuffle=False)\n",
    "\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        num_r_peaks = 0.0\n",
    "        num_correct = 0.0\n",
    "\n",
    "        all_outputs = []\n",
    "        all_labels = []\n",
    "        \n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (x_test, y_test) in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
    "                x, y = x_test.to(device), y_test.to(device)\n",
    "                outputs = self(x)\n",
    "\n",
    "                loss = self.criterion(outputs, y)\n",
    "                running_loss += loss.item()\n",
    "\n",
    "                outputs = outputs.cpu().detach().numpy()\n",
    "                y = y.cpu().detach().numpy()\n",
    "\n",
    "                num_r_peaks += np.where(y == 1)[0].shape[0]\n",
    "                num_correct += np.where((outputs > 0.5) & (y == 1))[0].shape[0]\n",
    "\n",
    "                all_outputs.extend(outputs.flatten())\n",
    "                all_labels.extend(y.flatten())\n",
    "\n",
    "                if plot and (i % (len(test_loader) / 10) == 0):\n",
    "                    ecg = x[0].cpu().detach().numpy()\n",
    "                    gt = y[0]\n",
    "                    pred = outputs[0]\n",
    "\n",
    "                    plt.figure()\n",
    "                    plt.plot(ecg)\n",
    "                    plt.plot(gt)\n",
    "                    plt.plot(pred)\n",
    "                    plt.legend([\"ECG\", \"Ground Truth\", \"Prediction\"])\n",
    "                    plt.grid()\n",
    "                    plt.show()\n",
    "                \n",
    "        all_outputs = np.array(all_outputs)\n",
    "        all_labels = np.array(all_labels)\n",
    "        y_pred_binary = (all_outputs > 0.5).astype(int)\n",
    "\n",
    "        print(f\"\\nTest Loss: {running_loss / len(test_loader):.4f}\")\n",
    "        self.calculate_metrics(num_correct, num_r_peaks, all_labels, y_pred_binary, phase=\"Test\")\n",
    "    \n",
    "    # we only care about the precision of the R_peaks (binary class 1) and we about the false positive rate\n",
    "    def calculate_metrics(self, num_correct_peaks, total_peaks, y_true, y_pred_binary, phase=\"Train\"):\n",
    "        accuracy = num_correct_peaks / total_peaks * 100\n",
    "\n",
    "        f1 = f1_score(y_true, y_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred_binary).ravel()\n",
    "        tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "\n",
    "        print(f\"{phase} Accuracy: {accuracy:.5f} %\")\n",
    "        print(f\"{phase} F1 Score: {f1:.5f}\")\n",
    "        print(f\"{phase} TPR: {tpr:.5f}\")\n",
    "        print(f\"{phase} FPR: {fpr:.5f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RPNet(\n",
       "  (d1): DownSample1DBlock(\n",
       "    (double_conv): DoubleConv1DBlock(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv1DBlock(\n",
       "          (conv1d): Conv1d(1, 16, kernel_size=(3,), stride=(1,), padding=same)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv1DBlock(\n",
       "          (conv1d): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=same)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (maxpool_1d): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (d2): DownSample1DBlock(\n",
       "    (double_conv): DoubleConv1DBlock(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv1DBlock(\n",
       "          (conv1d): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=same)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv1DBlock(\n",
       "          (conv1d): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=same)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (maxpool_1d): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (d3): DownSample1DBlock(\n",
       "    (double_conv): DoubleConv1DBlock(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv1DBlock(\n",
       "          (conv1d): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=same)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv1DBlock(\n",
       "          (conv1d): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (maxpool_1d): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (bottleneck): DoubleConv1DBlock(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv1DBlock(\n",
       "        (conv1d): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=same)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv1DBlock(\n",
       "        (conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=same)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (u1): UpSample1DBlock(\n",
       "    (conv1d_transpose): ConvTranspose1d(128, 64, kernel_size=(2,), stride=(2,))\n",
       "    (double_conv): DoubleConv1DBlock(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv1DBlock(\n",
       "          (conv1d): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=same)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv1DBlock(\n",
       "          (conv1d): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (u2): UpSample1DBlock(\n",
       "    (conv1d_transpose): ConvTranspose1d(64, 32, kernel_size=(2,), stride=(2,))\n",
       "    (double_conv): DoubleConv1DBlock(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv1DBlock(\n",
       "          (conv1d): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=same)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv1DBlock(\n",
       "          (conv1d): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=same)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (u3): UpSample1DBlock(\n",
       "    (conv1d_transpose): ConvTranspose1d(32, 16, kernel_size=(2,), stride=(2,))\n",
       "    (double_conv): DoubleConv1DBlock(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv1DBlock(\n",
       "          (conv1d): Conv1d(32, 16, kernel_size=(3,), stride=(1,), padding=same)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv1DBlock(\n",
       "          (conv1d): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=same)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (output): Conv1d(16, 1, kernel_size=(1,), stride=(1,))\n",
       "  (sigmoid): Sigmoid()\n",
       "  (criterion): BCELoss()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RPNet(in_channels=1, out_channels=1)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:41<00:00, 98.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Epoch [1/10]====\n",
      "\n",
      "Train Loss: 0.0163\n",
      "Train Accuracy: 66.32433 %\n",
      "Train F1 Score: 0.71314\n",
      "Train TPR: 0.66324\n",
      "Train FPR: 0.00220\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 281.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Loss: 0.0108\n",
      "Validation Accuracy: 77.32684 %\n",
      "Validation F1 Score: 0.79503\n",
      "Validation TPR: 0.77327\n",
      "Validation FPR: 0.00193\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:48<00:00, 91.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Epoch [2/10]====\n",
      "\n",
      "Train Loss: 0.0113\n",
      "Train Accuracy: 77.35587 %\n",
      "Train F1 Score: 0.78934\n",
      "Train TPR: 0.77356\n",
      "Train FPR: 0.00208\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 315.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Loss: 0.0094\n",
      "Validation Accuracy: 82.03463 %\n",
      "Validation F1 Score: 0.82623\n",
      "Validation TPR: 0.82035\n",
      "Validation FPR: 0.00185\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:39<00:00, 100.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Epoch [3/10]====\n",
      "\n",
      "Train Loss: 0.0104\n",
      "Train Accuracy: 79.22589 %\n",
      "Train F1 Score: 0.80552\n",
      "Train TPR: 0.79226\n",
      "Train FPR: 0.00195\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 290.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Loss: 0.0091\n",
      "Validation Accuracy: 81.79113 %\n",
      "Validation F1 Score: 0.82894\n",
      "Validation TPR: 0.81791\n",
      "Validation FPR: 0.00174\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:37<00:00, 102.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Epoch [4/10]====\n",
      "\n",
      "Train Loss: 0.0100\n",
      "Train Accuracy: 80.13325 %\n",
      "Train F1 Score: 0.81441\n",
      "Train TPR: 0.80133\n",
      "Train FPR: 0.00186\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 330.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Loss: 0.0086\n",
      "Validation Accuracy: 83.32431 %\n",
      "Validation F1 Score: 0.84136\n",
      "Validation TPR: 0.83324\n",
      "Validation FPR: 0.00165\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:31<00:00, 109.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Epoch [5/10]====\n",
      "\n",
      "Train Loss: 0.0097\n",
      "Train Accuracy: 80.77321 %\n",
      "Train F1 Score: 0.81995\n",
      "Train TPR: 0.80773\n",
      "Train FPR: 0.00181\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 324.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Loss: 0.0084\n",
      "Validation Accuracy: 83.40548 %\n",
      "Validation F1 Score: 0.84418\n",
      "Validation TPR: 0.83405\n",
      "Validation FPR: 0.00159\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:32<00:00, 107.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Epoch [6/10]====\n",
      "\n",
      "Train Loss: 0.0096\n",
      "Train Accuracy: 80.90917 %\n",
      "Train F1 Score: 0.82168\n",
      "Train TPR: 0.80909\n",
      "Train FPR: 0.00179\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 320.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Loss: 0.0081\n",
      "Validation Accuracy: 84.08189 %\n",
      "Validation F1 Score: 0.85126\n",
      "Validation TPR: 0.84082\n",
      "Validation FPR: 0.00151\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:36<00:00, 104.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Epoch [7/10]====\n",
      "\n",
      "Train Loss: 0.0094\n",
      "Train Accuracy: 81.34971 %\n",
      "Train F1 Score: 0.82618\n",
      "Train TPR: 0.81350\n",
      "Train FPR: 0.00174\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 304.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Loss: 0.0080\n",
      "Validation Accuracy: 83.84740 %\n",
      "Validation F1 Score: 0.85620\n",
      "Validation TPR: 0.83847\n",
      "Validation FPR: 0.00135\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:36<00:00, 103.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Epoch [8/10]====\n",
      "\n",
      "Train Loss: 0.0092\n",
      "Train Accuracy: 81.86548 %\n",
      "Train F1 Score: 0.82988\n",
      "Train TPR: 0.81865\n",
      "Train FPR: 0.00172\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 317.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Loss: 0.0079\n",
      "Validation Accuracy: 84.65007 %\n",
      "Validation F1 Score: 0.85776\n",
      "Validation TPR: 0.84650\n",
      "Validation FPR: 0.00143\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:33<00:00, 106.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Epoch [9/10]====\n",
      "\n",
      "Train Loss: 0.0091\n",
      "Train Accuracy: 82.10388 %\n",
      "Train F1 Score: 0.83207\n",
      "Train TPR: 0.82104\n",
      "Train FPR: 0.00170\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 313.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Loss: 0.0077\n",
      "Validation Accuracy: 85.60606 %\n",
      "Validation F1 Score: 0.86405\n",
      "Validation TPR: 0.85606\n",
      "Validation FPR: 0.00141\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:35<00:00, 104.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Epoch [10/10]====\n",
      "\n",
      "Train Loss: 0.0090\n",
      "Train Accuracy: 82.45830 %\n",
      "Train F1 Score: 0.83461\n",
      "Train TPR: 0.82458\n",
      "Train FPR: 0.00169\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 303.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Loss: 0.0078\n",
      "Validation Accuracy: 85.14610 %\n",
      "Validation F1 Score: 0.86113\n",
      "Validation TPR: 0.85146\n",
      "Validation FPR: 0.00141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.train_model(x_train=x_train, y_train=y_train, epochs=10, x_val=x_val, y_val=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
